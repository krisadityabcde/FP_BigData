version: '3.8'

# Hospital Big Data Pipeline with ML Services
# Services:
# - Zookeeper & Kafka: Message streaming infrastructure
# - Kafka-UI: Kafka monitoring interface
# - MinIO: Object storage for data and models
# - Data Producer: Streams hospital data to Consumer via Kafka
# - Data Consumer: Consumes from Kafka and stores to MinIO
# - Spark Trainer: ML training service for hospital predictions
# - API: REST API for real-time predictions
# - Spark Monitor: Monitoring service for training progress (optional)

services:
  # Zookeeper - Required for Kafka
  zookeeper:
    image: confluentinc/cp-zookeeper:7.4.0
    container_name: zookeeper
    environment:
      ZOOKEEPER_CLIENT_PORT: 2181
      ZOOKEEPER_TICK_TIME: 2000
    ports:
      - "2181:2181"
    networks:
      - bigdata-network

  # Kafka Broker
  kafka:
    image: confluentinc/cp-kafka:7.4.0
    container_name: kafka
    depends_on:
      - zookeeper
    ports:
      - "9092:9092"
      - "9101:9101"
    environment:
      KAFKA_BROKER_ID: 1
      KAFKA_ZOOKEEPER_CONNECT: 'zookeeper:2181'
      KAFKA_LISTENER_SECURITY_PROTOCOL_MAP: PLAINTEXT:PLAINTEXT,PLAINTEXT_HOST:PLAINTEXT
      KAFKA_ADVERTISED_LISTENERS: PLAINTEXT://kafka:29092,PLAINTEXT_HOST://localhost:9092
      KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: 1
      KAFKA_TRANSACTION_STATE_LOG_MIN_ISR: 1
      KAFKA_TRANSACTION_STATE_LOG_REPLICATION_FACTOR: 1
      KAFKA_GROUP_INITIAL_REBALANCE_DELAY_MS: 0
      KAFKA_JMX_PORT: 9101
      KAFKA_JMX_HOSTNAME: localhost
    networks:
      - bigdata-network

  # Kafka UI for monitoring
  kafka-ui:
    image: provectuslabs/kafka-ui:latest
    container_name: kafka-ui
    depends_on:
      - kafka
    ports:
      - "8080:8080"
    environment:
      KAFKA_CLUSTERS_0_NAME: local
      KAFKA_CLUSTERS_0_BOOTSTRAPSERVERS: kafka:29092
      KAFKA_CLUSTERS_0_ZOOKEEPER: zookeeper:2181
    networks:
      - bigdata-network
  minio:
    image: minio/minio:latest
    container_name: minio
    ports:
      - "9000:9000"
      - "9090:9090"  # Console port changed to 9090
    environment:
      MINIO_ROOT_USER: ${MINIO_ROOT_USER:-minioadmin}
      MINIO_ROOT_PASSWORD: ${MINIO_ROOT_PASSWORD:-minioadmin}
    command: server /data --console-address ":9090"
    volumes:
      - minio-data:/data
    networks:
      - bigdata-network
    restart: unless-stopped

  # Data Producer Service
  data-producer:
    build:
      context: ./services/data-producer
      dockerfile: Dockerfile
    container_name: data-producer
    depends_on:
      - kafka
    environment:
      KAFKA_BOOTSTRAP_SERVERS: kafka:29092
      KAFKA_TOPIC: hospital-data
    volumes:
      # Map local data folder to container data folder
      - ./services/data-producer/data:/app/data:ro
    networks:
      - bigdata-network
    restart: unless-stopped

  # Data Consumer Service (Kafka to MinIO)
  data-consumer:
    build:
      context: ./services/data-consumer
      dockerfile: Dockerfile
    container_name: data-consumer
    depends_on:
      - kafka
      - minio
    ports:
      - "5000:5000"  # Add port for REST API
    environment:
      KAFKA_BOOTSTRAP_SERVERS: kafka:29092
      KAFKA_TOPIC: hospital-data
      KAFKA_GROUP_ID: hospital-data-consumer
      MINIO_ENDPOINT: minio:9000
      MINIO_ACCESS_KEY: ${MINIO_ROOT_USER:-minioadmin}
      MINIO_SECRET_KEY: ${MINIO_ROOT_PASSWORD:-minioadmin}
      MINIO_BUCKET: hospital-data
    volumes:
      - ./services/data-consumer:/app
    networks:
      - bigdata-network
    restart: unless-stopped

  # Spark ML Trainer Service
  spark-trainer:
    build:
      context: ./services/spark-trainer
      dockerfile: Dockerfile
    container_name: spark-trainer
    depends_on:
      - minio
      - data-consumer
    environment:
      MINIO_ENDPOINT: minio:9000
      MINIO_ACCESS_KEY: ${MINIO_ROOT_USER:-minioadmin}
      MINIO_SECRET_KEY: ${MINIO_ROOT_PASSWORD:-minioadmin}
      MINIO_BUCKET: hospital-data
      MINIO_MODEL_BUCKET: hospital-models
      SPARK_MASTER: local[2]
      SPARK_DRIVER_MEMORY: 1g
      SPARK_EXECUTOR_MEMORY: 1g
      PYSPARK_PYTHON: python3
    volumes:
      - ./services/spark-trainer:/app
      - spark-models:/app/models
    networks:
      - bigdata-network
    restart: unless-stopped
    deploy:
      resources:
        limits:
          memory: 3g
          cpus: '2.0'
        reservations:
          memory: 1g
          cpus: '1.0'

  # Prediction API Service
  api:
    build:
      context: ./services/api
      dockerfile: Dockerfile
    container_name: prediction-api
    depends_on:
      - minio
      - spark-trainer
    ports:
      - "5001:5001"
    environment:
      MINIO_ENDPOINT: minio:9000
      MINIO_ACCESS_KEY: ${MINIO_ROOT_USER:-minioadmin}
      MINIO_SECRET_KEY: ${MINIO_ROOT_PASSWORD:-minioadmin}
      MINIO_MODEL_BUCKET: hospital-models
      FLASK_ENV: production
      FLASK_DEBUG: "false"
    volumes:
      - ./services/api:/app
    networks:
      - bigdata-network
    restart: unless-stopped
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:5001/health"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 60s

  # Spark Trainer Monitor Service
  spark-monitor:
    build:
      context: ./services/spark-trainer
      dockerfile: Dockerfile
    container_name: spark-monitor
    depends_on:
      - minio
    environment:
      MINIO_ENDPOINT: minio:9000
      MINIO_ACCESS_KEY: ${MINIO_ROOT_USER:-minioadmin}
      MINIO_SECRET_KEY: ${MINIO_ROOT_PASSWORD:-minioadmin}
      MINIO_BUCKET: hospital-data
      MINIO_MODEL_BUCKET: hospital-models
    volumes:
      - ./services/spark-trainer:/app
    networks:
      - bigdata-network
    restart: unless-stopped
    command: ["python", "monitor.py"]
    profiles:
      - monitoring

networks:
  bigdata-network:
    driver: bridge

volumes:
  kafka-data:
  zookeeper-data:
  minio-data:
  spark-models:
